# -*- coding: utf-8 -*-
"""Reccommendation_System_Game.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h8TP6KIT-WWf7MRTN4TgisbVx_mAmiM2

# Reccomendation System for Steam Game - Content-Based Filtering

- Author    : Muhammad Aditya Bayhaqie
- Practice  : Machine Learning Terapan (Dicoding)
- Dataset   : [Steam Games Kaggle](https://www.kaggle.com/datasets/fronkongames/steam-games-dataset/data?select=games.csv)

## Data Understanding

Mari panggil library dan dataset yang akan digunakan.
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import time
import random

from google.colab import drive
drive.mount('/content/drive')

! mkdir ~/.kaggle

!cp /content/drive/MyDrive/CollabData/kaggle_API/kaggle.json ~/.kaggle/kaggle.json

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download fronkongames/steam-games-dataset

!unzip steam-games-dataset.zip

"""### Data Assessment"""

games = pd.read_csv('/content/games.csv')

games.info()

"""Dari data tersebut, ditarik kesimpulan bahwa:
- Terdapat 39 **Kolom**
- Terdapat 111452 **Baris**
- Beberapa Kolom memiliki **Non-null** yang sedikit (`Score rank`, `Metacritic url`, `Reviews`) dan perlu ditangani dengan beberapa metode berupa
  - Drop Kolom
  - Isi Kolom kosong
"""

# Membaca dataset

df = games
df.head(5)

"""Dari data tersebut, Dapat disimpulkan bahwa Terjadi pergeseran konten data dari kolom `AppID` hingga `DiscountDLCcount`, `AppID` akan di drop karena data tersebut Insignifikan dan Kolom lainnya akan direname untuk memperbaiki konten data

### Data Preparation
"""

# Rename columns
df = df.rename(columns={
    'Price': 'DiscountDLC count',
    'Required age' : 'Price',
    'Peak CCU': 'Required age',
    'Estimated owners': 'Peak CCU',
    'Release date': 'Estimated owners',
    'Name': 'Release date',
    'AppID': 'Name',
})

# Reindex the DataFrame
df = df.reset_index(drop=True)

df.head(5)

# Drop the 8th column ('DiscountDLC count')
df = df.drop(df.columns[7], axis=1)

# Display the updated DataFrame (optional)
df.head(5)

"""## Exploratory Data Analysis

### Univariate Exploratory Data Analysis

`Game` Variable
"""

df.info()

"""Fitur `Release date` perlu diganti tipe datanya ke dates agar datanya dapat meproses masukan data lebih baik nantinya"""

print('Banyak data game yang terdaftar: ', len(df.Name.unique()))
print('Banyak game yang terdaftar: ', df.Name.unique())
print('List Game: ', df.Name.unique())

"""Terdapat 110326 data Game yang unik dengan 37 Fitur yang dapat digunakan

## Data Preprocessing

## Data Preparation

### Taking care on Missing Values
"""

# Mengecek missing value pada dataframe all_resto
df.isnull().sum()

"""#### `Name` Feature Treatment

Feature `Name` yang null akan didrop saja barisnya.
"""

df.dropna(subset=['Name'], inplace=True)
df.isnull().sum()

"""#### `About the game` Feature Treatment

Feature `About the game` akan diganti dengan data

```
No Description
```
"""

df['About the game'] = df['About the game'].fillna('No Description')
df.isnull().sum()

"""#### `Reviews`, `Website`, `Support url`, `Support email`, `Metacritic url`, `Metacritic score`, `Average playtime two weeks`,`Median playtime two weeks`, `Score rank` and `Notes` Feature Treatment

Fitur `Reviews`, `Website`, `Support url`, `Support email`, `Metacritic url`, `Metacritic score`, `Average playtime two weeks`,`Median playtime two weeks`, `Score rank` dan `Notes` akan didrop saja kolomnya

*PS: Data ini dapat digunakan sebagai pelengkap deskripsi game yang akan kita rekomendasikan, namun untuk kali ini datanya akan didrop saja*
"""

# Drop specified columns
columns_to_drop = ['Reviews', 'Website', 'Support url', 'Support email', 'Metacritic url' , 'Metacritic score' , 'Score rank', 'Notes', 'Average playtime two weeks', 'Median playtime two weeks']
df = df.drop(columns=columns_to_drop)

df.isnull().sum()

"""#### `Developers` Feature Treatment

Feature `Developers` yang null akan didrop saja barisnya.
"""

df.dropna(subset=['Developers'], inplace=True)
df.isnull().sum()

"""#### `Publishers` Feature Treatment

Feature `Publishers` yang null akan kita samakan dengan developers
"""

publishers_with_null = df[df['Publishers'].isnull()]
print("Publishers with null data:")
display(publishers_with_null[['Name','Developers', 'Publishers']])

df['Publishers'].fillna(df['Developers'], inplace=True)
df.isnull().sum()

"""#### `Categories` Feature Treatment"""

display(df.head())

display(df[df['Categories'].isnull()])

"""Data null pada `Categories` akan kita drop saja"""

df.dropna(subset=['Categories'], inplace=True)
df.isnull().sum()

"""#### `Screenshots` , `Movies` and `Header image` Feature Treatment

Untuk fitur `Screenshots` and `Movies` akan didrop saja karena tidak relevan untuk keperluan sistem rekomendasi nantinya

*PS: Data ini dapat digunakan sebagai pelengkap deskripsi game yang akan kita rekomendasikan, namun untuk kali ini datanya akan didrop saja*
"""

# Drop specified columns
columns_to_drop = ['Screenshots', 'Movies', 'Header image']
df = df.drop(columns=columns_to_drop)

df.isnull().sum()

"""#### `Genres` Feature Treatment

Untuk fitur `Genres` akan didrop saja baris Null karena jumlah data Null yang sedikit
"""

df.dropna(subset=['Genres'], inplace=True)
df.isnull().sum()

"""#### `Release date` Feature Treatment

Untuk fitur `Release date` akan didrop saja baris Null karena jumlah data Null yang sedikit
"""

df.dropna(subset=['Release date'], inplace=True)
df.isnull().sum()

"""#### `Tags` Feature Treatment

Untuk fitur `Tags` akan diisi dengan data pada `Genres`
"""

df['Tags'].fillna(df['Genres'], inplace=True)
df.isnull().sum()

"""### Data Type Modification"""

# Change 'Release date' to datetime
df['Release date'] = pd.to_datetime(df['Release date'], format='%b %d, %Y', errors='coerce')
df.info()
df.head()

display(df)

"""### Value Modification"""

df.info()

"""#### Data Modification on `Supported languages` and `Full audio languages`

Data yang mengandung

```
[]
```

Pada `Supported languages` dan `Full audio languages` akan diganti dengan

```
No Supporting Languages / No Full audio languages
```
"""

# Function to check and replace empty lists, and count occurrences
def replace_empty_lists_and_count(df, column_name):
  empty_list_count = 0
  for index, value in df[column_name].items():
    if value == '[]':
      df.loc[index, column_name] = f'No {column_name}'
      empty_list_count += 1
  return df, empty_list_count

# Process 'Supported languages' column
df, supported_languages_count = replace_empty_lists_and_count(df, 'Supported languages')
print(f"Number of entries with '[]' in 'Supported languages': {supported_languages_count}")

# Process 'Full audio languages' column
df, full_audio_languages_count = replace_empty_lists_and_count(df, 'Full audio languages')
print(f"Number of entries with '[]' in 'Full audio languages': {full_audio_languages_count}")

# Display rows that originally contained '[]' in either column (now replaced)
display(df[
    (df['Supported languages'] == 'No Supported languages') |
    (df['Full audio languages'] == 'No Full audio languages')
])

df.head()

"""### Feature Consideration

### Dropping Duplicates

Pada bagian ini, akan diidentifikasi dan dihapus baris-baris yang memiliki nilai duplikat pada kolom `Name`. Karena setiap nama game seharusnya unik dalam dataset, baris duplikat berdasarkan nama game menunjukkan entri yang redundant dan perlu dihapus untuk memastikan kebersihan data dan mencegah bias dalam analisis atau pemodelan.

Langkah-langkahnya adalah sebagai berikut:

1.  **Memeriksa jumlah data duplikat:** Dihitung berapa banyak baris yang memiliki nilai `Name` yang sama dengan baris sebelumnya menggunakan `.duplicated()`.
2.  **Menghapus data duplikat:** Dihapus baris duplikat berdasarkan kolom `Name` dengan menggunakan `.drop_duplicates()`. Parameter `keep='first'` (default) akan mempertahankan baris pertama yang muncul dan menghapus sisanya.
3.  **Memverifikasi jumlah data setelah penghapusan:** Ditampilkan jumlah baris dalam DataFrame setelah data duplikat dihapus untuk memastikan operasi berhasil.
"""

print(f'Jumlah game duplikat: {df.Name.duplicated().sum()}')
print(f'Jumlah game sebelum menghapus duplikat: {len(df)}')

df = df.drop_duplicates('Name')
print(f'Jumlah game setelah menghapus duplikat: {len(df)}')

df.info()

"""### Data Selection and Conversion

Setelah proses pembersihan dan penanganan nilai yang hilang selesai, tahap selanjutnya adalah memilih fitur-fitur yang relevan untuk digunakan dalam proses pemodelan sistem rekomendasi dan mengubahnya menjadi format yang sesuai.

Pada bagian ini, dilakukan hal berikut:

1.  **Pemilihan Kolom:** Kolom-kolom spesifik dari DataFrame `df` yang dianggap penting untuk membangun profil konten setiap game dipilih. Kolom-kolom ini meliputi `Name`, `Release date`, `Required age`, `Supported languages`, `Full audio languages`, `Windows`, `Mac`, `Linux`, `Average playtime forever`, `Categories`, dan `Tags`.
2.  **Konversi ke List:** Setiap kolom yang dipilih dikonversi menjadi Python list. Ini dilakukan untuk memudahkan penggunaan data dalam struktur data yang lebih sederhana dan mudah diakses, yang akan digunakan untuk membuat DataFrame baru yang lebih ringkas dan fokus pada fitur-fitur yang dipilih.
3.  **Verifikasi Panjang List:** Panjang (jumlah elemen) dari setiap list yang baru dibuat dicetak untuk memastikan bahwa proses konversi berhasil dan semua data dari kolom yang dipilih telah dimasukkan ke dalam list masing-masing.
"""

Name = df['Name'].tolist()
print(len(Name))
Release_date = df['Release date'].tolist()
print(len(Release_date))
Required_age = df['Required age'].tolist()
print(len(Required_age))
Supported_languages = df['Supported languages'].tolist()
print(len(Supported_languages))
Full_audio_languages = df['Full audio languages'].tolist()
print(len(Full_audio_languages))
Windows = df['Windows'].tolist()
print(len(Windows))
Mac = df['Mac'].tolist()
print(len(Mac))
Linux = df['Linux'].tolist()
print(len(Linux))
Average_playtime_forever = df['Average playtime forever'].tolist()
print(len(Average_playtime_forever))
Categories = df['Categories'].tolist()
print(len(Categories))
Tags = df['Tags'].tolist()
print(len(Tags))

"""### Dictionary Making

Pada bagian ini, DataFrame baru bernama `games_df` dibuat. DataFrame ini disusun menggunakan list-list data yang telah dipilih dan dikonversi pada langkah sebelumnya, seperti `Name`, `Release date`, `Required age`, dan seterusnya.

Tujuannya adalah untuk mengorganisir fitur-fitur game yang relevan ke dalam satu struktur DataFrame yang ringkas dan siap untuk tahap pemrosesan selanjutnya. Setiap kolom dalam DataFrame ini merepresentasikan fitur spesifik dari game.

Setelah DataFrame `games_df` dibuat, lima baris pertamanya ditampilkan untuk memberikan gambaran awal tentang struktur dan isi data yang telah digabungkan.
"""

games_df = pd.DataFrame({
    'Name': Name,
    'Release date': Release_date,
    'Required age': Required_age,
    'Supported languages': Supported_languages,
    'Full audio languages': Full_audio_languages,
    'Windows': Windows,
    'Mac': Mac,
    'Linux': Linux,
    'Average playtime forever': Average_playtime_forever,
    'Categories': Categories,
    'Tags': Tags
})

display(games_df)

"""#### Dictionary Reduction

Pada bagian ini, ukuran DataFrame `games_df` dikurangi. Tujuannya adalah untuk mempercepat proses eksperimen dan pengembangan model dengan bekerja pada subset data yang lebih kecil, namun tetap merepresentasikan karakteristik data asli.

Langkah-langkah yang dilakukan:

1.  **Menghitung jumlah baris total:** Diambil jumlah total baris dalam DataFrame `games_df`.
2.  **Menghitung jumlah baris yang dikurangi:** Dihitung jumlah baris target setelah pengurangan. Dalam kasus ini, diambil 20% dari jumlah baris total.
3.  **Mengambil sampel acak:** DataFrame `games_df` diubah dengan mengambil sampel acak sebanyak jumlah baris yang telah dihitung. `random_state=42` digunakan untuk memastikan hasil sampel konsisten setiap kali kode dijalankan.
4.  **Reset Indeks:** Indeks DataFrame direset untuk membuat indeks baru yang berurutan setelah pengambilan sampel.
5.  **Menampilkan informasi pengurangan:** Dicetak pesan yang menunjukkan jumlah baris setelah pengurangan untuk memverifikasi proses.
"""

total_rows = len(games_df)
reduced_rows = int(total_rows * 0.20)
games_df = games_df.sample(n=reduced_rows, random_state=42).reset_index(drop=True)
print(f"Reduced dataset to {len(games_df)} rows (approximately 20%).")

"""##### `Categories` and `Tags` Value Normalization

Pada langkah ini, dilakukan normalisasi pada nilai-nilai dalam kolom `Categories` dan `Tags` untuk menyederhanakan dan mengekstrak informasi relevan.

Untuk kolom `Categories`, sebuah fungsi diterapkan untuk mengidentifikasi keberadaan kategori spesifik seperti 'Single-player', 'Multi-player', 'Steam Achievements', 'Family Sharing', dan 'Full controller support'. Berdasarkan kategori-kategori ini, dibuat fitur baru:
-   `Player based`: Menentukan apakah game berorientasi 'Single' (hanya single-player), 'Multi' (multi-player), atau keduanya.
-   `Steam Achievements`: Menunjukkan apakah game memiliki pencapaian Steam (Boolean).
-   `Family Sharing`: Menunjukkan apakah game mendukung Family Sharing (Boolean).
-   `Full controller support`: Menunjukkan apakah game mendukung kontroler penuh (Boolean).

Untuk kolom `Tags`, sebuah fungsi diterapkan untuk mengekstrak tiga tag pertama (jika ada). Ini menghasilkan tiga fitur baru:
-   `Tag 1`: Tag pertama.
-   `Tag 2`: Tag kedua.
-   `Tag 3`: Tag ketiga.

Selanjutnya, untuk kolom `Supported languages` dan `Full audio languages`, sebuah fungsi diterapkan untuk menghitung jumlah bahasa yang terdaftar. Nilai 'No Supported languages' atau 'No Full audio languages' diperlakukan sebagai 0 bahasa. Hasilnya adalah nilai numerik yang merepresentasikan jumlah bahasa yang didukung atau bahasa audio penuh.

Setelah fitur-fitur baru dibuat, kolom asli `Categories` dan `Tags` dihapus dari DataFrame karena informasi relevan telah diekstraksi dan dinormalisasi ke dalam kolom-kolom baru. DataFrame yang diperbarui kemudian ditampilkan.
"""

def process_categories_refined(categories_str):
    categories = categories_str.split(',')
    single_player = 'Single-player' in categories
    multi_player = 'Multi-player' in categories

    # Determine Player based: Multi if both are present, Single if only Single-player, None otherwise
    if single_player and multi_player:
        player_based = 'Multi'
    elif single_player:
        player_based = 'Single'
    else:
        player_based = 'Single' # Or handle cases where neither is present

    steam_achievements = 'Steam Achievements' in categories
    family_sharing = 'Family Sharing' in categories
    full_controller_support = 'Full controller support' in categories

    return player_based, steam_achievements, family_sharing, full_controller_support

# Apply the refined function to the Categories column
games_df['Player based'] = games_df['Categories'].apply(lambda x: process_categories_refined(x)[0])
games_df['Steam Achievements'] = games_df['Categories'].apply(lambda x: process_categories_refined(x)[1])
games_df['Family Sharing'] = games_df['Categories'].apply(lambda x: process_categories_refined(x)[2])
games_df['Full controller support'] = games_df['Categories'].apply(lambda x: process_categories_refined(x)[3])

# Function to process Tags
def process_tags(tags_str):
    tags = tags_str.split(',')
    tag1 = tags[0].strip() if len(tags) > 0 else None
    tag2 = tags[1].strip() if len(tags) > 1 else None
    tag3 = tags[2].strip() if len(tags) > 2 else None
    return tag1, tag2, tag3

# Apply the function to the Tags column
games_df['Tag 1'] = games_df['Tags'].apply(lambda x: process_tags(x)[0])
games_df['Tag 2'] = games_df['Tags'].apply(lambda x: process_tags(x)[1])
games_df['Tag 3'] = games_df['Tags'].apply(lambda x: process_tags(x)[2])


# Display the updated DataFrame
display(games_df.head())

# Function to count languages, handling the specific "No" strings
def count_languages(language_str):
    if language_str in ['No Supported languages', 'No Full audio languages']:
        return 0
    # Assuming the language strings are comma-separated (and possibly have leading/trailing spaces)
    languages = [lang.strip() for lang in language_str.split(',') if lang.strip()]
    return len(languages)

# Apply the function to the 'Supported languages' and 'Full audio languages' columns
games_df['Supported languages'] = games_df['Supported languages'].apply(count_languages)
games_df['Full audio languages'] = games_df['Full audio languages'].apply(count_languages)

# Display the updated DataFrame with the new count columns
display(games_df.head())

# You can also display the info to see the new columns
games_df.info()

"""Drop kolom utama"""

games_df = games_df.drop(columns=['Categories', 'Tags'])
display(games_df.head())

display(games_df)

"""### Data Randomizing

Pada bagian ini, data dalam DataFrame `games_df` diacak secara acak. Tujuannya adalah untuk memastikan bahwa urutan data tidak bias dan siap untuk tahap pembagian data menjadi set pelatihan dan validasi pada langkah selanjutnya. Pengacakan ini penting untuk menghindari model belajar dari urutan data tertentu.

Langkah-langkah yang dilakukan:

1.  **Mengacak DataFrame:** DataFrame `games_df` diacak menggunakan `.sample(frac=1)`. Parameter `frac=1` memastikan bahwa seluruh data diambil sebagai sampel. `random_state=42` digunakan untuk membuat hasil pengacakan dapat direproduksi.
2.  **Memisahkan Fitur dan Target:** Kolom `Name` dipisahkan sebagai variabel target (`y`), dan semua kolom lainnya dianggap sebagai fitur (`X`).
3.  **Membagi Data Latih dan Validasi:** Data `X` dan `y` dibagi menjadi set pelatihan (80%) dan set validasi (20%) berdasarkan indeks baris yang telah diacak.
4.  **Menampilkan Bentuk Data:** Bentuk (jumlah baris dan kolom) dari DataFrame `X`, `y`, `X_train`, `X_val`, `y_train`, dan `y_val` dicetak untuk memverifikasi hasil pembagian data.
"""

# Mengacak dataset
games_df = games_df.sample(frac=1, random_state=42)
games_df

# Mengambil semua kolom kecuali 'Name' sebagai fitur (X)
X = games_df.drop('Name', axis=1)
# Mengambil kolom 'Name' sebagai target (y)
y = games_df['Name']

# Membagi data menjadi 80% data latih dan 20% data validasi
train_indices = int(0.8 * games_df.shape[0])

X_train, X_val = (
    X[:train_indices],
    X[train_indices:]
)

y_train, y_val = (
    y[:train_indices],
    y[train_indices:]
)

print("Bentuk data X (fitur):", X.shape)
print("Bentuk data y (target):", y.shape)
print("Bentuk data X_train:", X_train.shape)
print("Bentuk data X_val:", X_val.shape)
print("Bentuk data y_train:", y_train.shape)
print("Bentuk data y_val:", y_val.shape)

print(X,y)

"""## Model Development using Content-Based Filtering

Pada tahap ini, model menghitung skor kecocokan antar game berdasarkan kesamaan kontennya (kategori, tag, dll.). Pertama, kita melakukan proses vektorisasi (mengubah teks menjadi angka) pada fitur-fitur game. Selanjutnya, hitung kesamaan kosinus antar vektor game. Hasilnya adalah daftar game yang paling mirip dengan game yang diberikan sebagai masukan.
"""

# Menggabungkan fitur teks yang relevan untuk Content-Based Filtering
games_df['features'] = games_df[['Release date', 'Required age', 'Supported languages',
                                 'Full audio languages', 'Windows', 'Mac', 'Linux',
                                 'Average playtime forever', 'Player based',
                                 'Steam Achievements', 'Family Sharing',
                                 'Full controller support', 'Tag 1', 'Tag 2', 'Tag 3']].astype(str).agg(' '.join, axis=1)

# Inisialisasi TfidfVectorizer
# Menghapus stop words umum bisa membantu, tetapi tergantung pada fitur teks yang digunakan
tfidf = TfidfVectorizer(stop_words='english')

# Melakukan fit dan transform pada fitur yang digabungkan
tfidf_matrix = tfidf.fit_transform(games_df['features'])

print("Bentuk matriks TF-IDF:", tfidf_matrix.shape)

# Menghitung kemiripan kosinus antar game
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print("Bentuk matriks kemiripan kosinus:", cosine_sim.shape)

# Membuat mapping dari nama game ke indeksnya dalam matriks kemiripan
indices = pd.Series(games_df.index, index=games_df['Name']).drop_duplicates()

def get_recommendations(game_name, cosine_sim=cosine_sim, df=games_df, indices=indices):
    """
    Memberikan rekomendasi game berdasarkan kemiripan konten.

    Args:
        game_name (str): Nama game yang ingin dicari rekomendasinya.
        cosine_sim (numpy.ndarray): Matriks kemiripan kosinus.
        df (pd.DataFrame): DataFrame yang berisi data game.
        indices (pd.Series): Series mapping nama game ke indeks.

    Returns:
        pd.DataFrame: DataFrame berisi 10 game teratas yang direkomendasikan
                      beserta skor kemiripannya.
    """
    # Mengambil indeks game yang namanya sesuai
    # Menggunakan .loc untuk akses berdasarkan label indeks Series
    try:
        idx = indices.loc[game_name]
    except KeyError:
        print(f"Game '{game_name}' not found in the dataset.")
        return pd.DataFrame() # Return an empty DataFrame if game not found

    # Mengambil skor kemiripan dari game tersebut dengan semua game lain
    # Jika idx adalah skalar (untuk satu game), langsung ambil baris dari cosine_sim
    if isinstance(idx, (int, np.integer)):
        sim_scores = list(enumerate(cosine_sim[idx]))
    # Jika idx adalah Series (untuk multiple games with the same name - should not happen after drop_duplicates,
    # but good practice to handle), take the first index.
    elif isinstance(idx, pd.Series):
         # Assuming we take the first index if multiple matches exist
         idx = idx.iloc[0]
         sim_scores = list(enumerate(cosine_sim[idx]))
    else:
        print(f"Unexpected index type for game '{game_name}'.")
        return pd.DataFrame()


    # Mengurutkan game berdasarkan skor kemiripan secara menurun
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Mengambil skor 11 game teratas (idx 0 adalah game itu sendiri)
    sim_scores = sim_scores[1:11] # Get the top 10 most similar games (excluding the input game)

    # Mengambil indeks game-game yang direkomendasikan
    game_indices = [i[0] for i in sim_scores]

    # Membuat DataFrame hasil rekomendasi
    # Use the original DataFrame index to get the actual game data
    recommended_games = df.iloc[game_indices].copy()

    # Add the similarity score to the recommended games DataFrame
    recommended_games['Similarity Score'] = [i[1] for i in sim_scores]

    # Add the 'Tag 1' feature to the output for better interpretability
    recommended_games['Tag 1'] = games_df.loc[game_indices, 'Tag 1'].values


    return recommended_games[['Name', 'Tag 1', 'Similarity Score']]

# Contoh penggunaan: Mendapatkan rekomendasi untuk game tertentu
game_to_recommend = 'Alien Invasion 3d'

def recommend_and_evaluate_content_based(game_name, N=10):
    if game_name not in indices:
        print(f"Game '{game_name}' not found in the dataset.")
        return None, None

    print(f"Generating Top-{N} recommendations for '{game_name}'...")

    # Get the index of the input game
    idx = indices[game_name]

    # Get the similarity scores for all games with this game
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the games based on similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the top N+1 most similar games (excluding the game itself)
    sim_scores = sim_scores[1:N+1]

    # Get the indices of the recommended games
    game_indices = [i[0] for i in sim_scores]

    # Get the recommended game names
    recommended_games = games_df['Name'].iloc[game_indices]

    print("\nRecommended Games (Content-Based):")
    display(recommended_games)

    print(f"\nFeatures related to '{game_name}':")
    display(games_df[games_df['Name'] == game_name][['Release date', 'Required age', 'Supported languages',
                                                     'Full audio languages', 'Windows', 'Mac', 'Linux',
                                                     'Average playtime forever', 'Player based',
                                                     'Steam Achievements', 'Family Sharing',
                                                     'Full controller support', 'Tag 1', 'Tag 2', 'Tag 3']])

    print(f"\nPerforming Qualitative Evaluation: Precision@{N}")

    # Simple simulation of relevance: Assume a recommendation is "relevant"
    # if its similarity score is above a certain threshold (e.g., > 0.7)

    input_game_tags = games_df[games_df['Name'] == game_name][['Tag 1']].iloc[0].tolist()
    relevant_count = 0
    total_recommendations = N

    for rec_idx, score in sim_scores:
        recommended_game_name = games_df['Name'].iloc[rec_idx]
        recommended_game_tags = games_df[games_df['Name'] == recommended_game_name][['Tag 1']].iloc[0].tolist()

        # Check for simulated relevance: high score AND shared Tag 1
        if score > 0.7:
             relevant_count += 1
             print(f" - '{recommended_game_name}' (Score: {score:.2f}) - Simulated Relevant") # Optional: Print relevant ones
        else:
             print(f" - '{recommended_game_name}' (Score: {score:.2f}) - Simulated Not Relevant") # Optional: Print non-relevant ones


    precision_at_N = relevant_count / total_recommendations if total_recommendations > 0 else 0

    print(f"\nSimulated Relevant Recommendations out of {N}: {relevant_count}")
    print(f"Precision@{N}: {precision_at_N:.4f}")

    return recommended_games, precision_at_N

recommended_games, precision = recommend_and_evaluate_content_based(game_to_recommend, N=10)

# Contoh penggunaan: Mendapatkan rekomendasi untuk game tertentu
game_to_recommend = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

recommended_games, precision = recommend_and_evaluate_content_based(game_to_recommend, N=10)

# Contoh penggunaan: Mendapatkan rekomendasi untuk game tertentu
game_to_recommend = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

recommended_games, precision = recommend_and_evaluate_content_based(game_to_recommend, N=10)

# Contoh penggunaan: Mendapatkan rekomendasi untuk game tertentu
game_to_recommend = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

recommended_games, precision = recommend_and_evaluate_content_based(game_to_recommend, N=10)

# Contoh penggunaan: Mendapatkan rekomendasi untuk game tertentu
game_to_recommend = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

recommended_games, precision = recommend_and_evaluate_content_based(game_to_recommend, N=10)

"""## Model Development using Deep Content Filtering

Meskipun dataset ini tidak memiliki data interaksi pengguna (seperti rating atau playtime per user) yang ideal untuk model seperti RecommenderNet, kita bisa mengadaptasi idenya.

RecommenderNet biasanya menggabungkan embedding dari pengguna dan item. Karena tidak ada pengguna, kita bisa mencoba membuat embedding hanya untuk item (game) berdasarkan fitur kontennya.

Ide:
1. Buat layer embedding untuk setiap fitur kategorikal (misalnya, Player based, Tag 1, Tag 2, Tag 3).
2. Buat layer input untuk fitur numerik (misalnya, Required age, Supported languages, dll.).
3. Gabungkan embedding dan input numerik.
4. Lewatkan melalui beberapa dense layer.
5. Output layer bisa berupa embedding vektor game. Kemiripan antar game kemudian dihitung dari embedding ini.
"""

# Fitur kategorikal yang akan di-encode
categorical_features = ['Player based', 'Steam Achievements', 'Family Sharing',
                        'Full controller support', 'Tag 1', 'Tag 2', 'Tag 3',
                        'Windows', 'Mac', 'Linux'] # Include platform features

# Salinan data untuk encoding
games_encoded = games_df.copy()

# Dictionary untuk menyimpan encoder
label_encoders = {}

for col in categorical_features:
    le = LabelEncoder()
    # Handle potential NaN values that might appear after drops/preprocessing
    games_encoded[col] = games_encoded[col].astype(str) # Ensure all are strings before encoding
    games_encoded[col] = le.fit_transform(games_encoded[col])
    label_encoders[col] = le # Store the encoder

# Fitur numerik
numerical_features = ['Required age', 'Supported languages', 'Full audio languages', 'Average playtime forever']

# Normalisasi fitur numerik (Opsional tapi direkomendasikan)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
games_encoded[numerical_features] = scaler.fit_transform(games_encoded[numerical_features])

# Buat input layers
input_layers = []
embedding_layers = []
dense_inputs = []

# Input dan embedding untuk fitur kategorikal
for col in categorical_features:
    num_unique_values = len(label_encoders[col].classes_)
    embedding_dim = max(2, min(50, num_unique_values // 2)) # Heuristik sederhana untuk dimensi embedding

    input_layer = keras.Input(shape=(1,), name=f'input_{col}')
    # Modify the layer name to replace spaces with underscores
    cleaned_col_name = col.replace(" ", "_")
    embedding_layer = layers.Embedding(input_dim=num_unique_values, output_dim=embedding_dim, name=f'embedding_{cleaned_col_name}')(input_layer)
    flatten_layer = layers.Flatten()(embedding_layer)

    input_layers.append(input_layer)
    embedding_layers.append(flatten_layer)

# Input untuk fitur numerik
for col in numerical_features:
    input_layer = keras.Input(shape=(1,), name=f'input_{col}')
    input_layers.append(input_layer)
    dense_inputs.append(input_layer)

# Gabungkan semua embedding dan input numerik
# Pastikan embedding_layers dan dense_inputs tidak kosong
if embedding_layers and dense_inputs:
    concat_layer = layers.concatenate(embedding_layers + dense_inputs)
elif embedding_layers:
     concat_layer = layers.concatenate(embedding_layers)
elif dense_inputs:
    concat_layer = layers.concatenate(dense_inputs)
else:
    raise ValueError("Tidak ada fitur yang tersedia untuk model.")

# Dense layers (arsitektur mirip RecommenderNet)
x = layers.Dense(128, activation='relu')(concat_layer)
x = layers.Dropout(0.2)(x)
x = layers.Dense(64, activation='relu')(x)
x = layers.Dropout(0.2)(x)

# Output layer: Representasi embedding game (misalnya, 32 dimensi)
game_embedding = layers.Dense(32, activation='linear', name='game_embedding')(x) # Linear activation for embedding

# Model
recommender_model = keras.Model(inputs=input_layers, outputs=game_embedding)

recommender_model.summary()

# Mendapatkan embedding untuk semua game
# Siapkan input data dalam format yang sesuai untuk model
model_inputs = {}
for col in categorical_features + numerical_features:
     # Ensure correct data type for model input
    if col in categorical_features:
        model_inputs[f'input_{col}'] = games_encoded[col].values
    else: # numerical_features
        model_inputs[f'input_{col}'] = games_encoded[col].values

# Ubah dictionary input menjadi list sesuai urutan input_layers di model
ordered_model_inputs = [model_inputs[input_layer.name] for input_layer in recommender_model.inputs]


game_embeddings = recommender_model.predict(ordered_model_inputs)

print("Bentuk matriks embedding game:", game_embeddings.shape)

# Menghitung kemiripan kosinus antar embedding game
cosine_sim_deep = cosine_similarity(game_embeddings, game_embeddings)

print("Bentuk matriks kemiripan kosinus (Deep):", cosine_sim_deep.shape)

# Fungsi untuk mendapatkan rekomendasi menggunakan embedding dari model "Deep"
def get_deep_content_based_recommendations(game_name, cosine_sim=cosine_sim_deep, games_df=games_df, indices=indices):
    # Mendapatkan indeks dari game yang namanya cocok
    # Pastikan indeks Series menggunakan index dari games_df, bukan games_encoded
    idx = indices[game_name]

    # Mendapatkan skor kemiripan dari semua game dengan game ini
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Mengurutkan game berdasarkan skor kemiripan secara menurun
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Mengambil skor dari 10 game paling mirip (kecuali game itu sendiri)
    sim_scores = sim_scores[1:11]

    # Mendapatkan indeks game
    game_indices = [i[0] for i in sim_scores]

    # Mengembalikan nama game yang paling mirip
    return games_df['Name'].iloc[game_indices]

def recommend_and_evaluate_deep_content_based(game_name, N=10, cosine_sim=cosine_sim_deep):
    if game_name not in indices:
        print(f"Game '{game_name}' not found in the dataset.")
        return None, None

    print(f"Generating Top-{N} recommendations for '{game_name}' using Deep Content-Based Model...")

    # Get the index of the input game
    idx = indices[game_name]

    # Get the similarity scores for all games with this game
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the games based on similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the top N+1 most similar games (excluding the game itself)
    sim_scores = sim_scores[1:N+1]

    # Get the indices of the recommended games
    game_indices = [i[0] for i in sim_scores]

    # Get the recommended game names
    recommended_games = games_df['Name'].iloc[game_indices]

    print("\nRecommended Games (Deep Content-Based):")
    display(recommended_games)

    print(f"\nFeatures related to '{game_name}':")
    display(games_df[games_df['Name'] == game_name][['Release date', 'Required age', 'Supported languages',
                                                     'Full audio languages', 'Windows', 'Mac', 'Linux',
                                                     'Average playtime forever', 'Player based',
                                                     'Steam Achievements', 'Family Sharing',
                                                     'Full controller support', 'Tag 1', 'Tag 2', 'Tag 3']])


    print(f"\nPerforming Qualitative Evaluation: Precision@{N}")

    # Simple simulation of relevance for Deep Model:
    # Assume a recommendation is "relevant" if its similarity score is above a certain threshold (e.g., > 0.6 for Deep)
    # AND it shares at least one 'Tag 1' with the original game.
    # The threshold might need tuning based on the distribution of similarity scores from the deep model.
    relevance_threshold = 0.6

    input_game_tags = games_df[games_df['Name'] == game_name][['Tag 1']].iloc[0].tolist()
    relevant_count = 0
    total_recommendations = N

    for rec_idx, score in sim_scores:
        recommended_game_name = games_df['Name'].iloc[rec_idx]
        recommended_game_tags = games_df[games_df['Name'] == recommended_game_name][['Tag 1']].iloc[0].tolist()

        # Check for simulated relevance: high score AND shared Tag 1
        if score > relevance_threshold:
             relevant_count += 1
             print(f" - '{recommended_game_name}' (Score: {score:.4f}) - Simulated Relevant") # Optional: Print relevant ones
        else:
             print(f" - '{recommended_game_name}' (Score: {score:.4f}) - Simulated Not Relevant") # Optional: Print non-relevant ones


    precision_at_N = relevant_count / total_recommendations if total_recommendations > 0 else 0

    print(f"\nSimulated Relevant Recommendations out of {N}: {relevant_count}")
    print(f"Precision@{N}: {precision_at_N:.4f}")


    return recommended_games, precision_at_N

game_to_recommend_deep = 'Ozone Guardian' # Choose another game from your reduced dataset

# Find a game that is definitely in the reduced dataset to test with
print(f"\nTesting Deep Content-Based Recommender with: '{game_to_recommend_deep}'")

recommended_games_deep, precision_deep = recommend_and_evaluate_deep_content_based(game_to_recommend_deep, N=10, cosine_sim=cosine_sim_deep)

game_to_recommend_deep = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

# Find a game that is definitely in the reduced dataset to test with
print(f"\nTesting Deep Content-Based Recommender with: '{game_to_recommend_deep}'")

recommended_games_deep, precision_deep = recommend_and_evaluate_deep_content_based(game_to_recommend_deep, N=10, cosine_sim=cosine_sim_deep)

game_to_recommend_deep = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

# Find a game that is definitely in the reduced dataset to test with
print(f"\nTesting Deep Content-Based Recommender with: '{game_to_recommend_deep}'")

recommended_games_deep, precision_deep = recommend_and_evaluate_deep_content_based(game_to_recommend_deep, N=10, cosine_sim=cosine_sim_deep)

game_to_recommend_deep = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

# Find a game that is definitely in the reduced dataset to test with
print(f"\nTesting Deep Content-Based Recommender with: '{game_to_recommend_deep}'")

recommended_games_deep, precision_deep = recommend_and_evaluate_deep_content_based(game_to_recommend_deep, N=10, cosine_sim=cosine_sim_deep)

game_to_recommend_deep = games_df['Name'].iloc[random.randint(0, len(games_df) - 1)]

# Find a game that is definitely in the reduced dataset to test with
print(f"\nTesting Deep Content-Based Recommender with: '{game_to_recommend_deep}'")

recommended_games_deep, precision_deep = recommend_and_evaluate_deep_content_based(game_to_recommend_deep, N=10, cosine_sim=cosine_sim_deep)

